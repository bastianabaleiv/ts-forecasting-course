---
title: "Clase 3"
description: |
  Series de tiempo en R: evaluando modelos basados en caracter√≠sticas
author:
  - name: Basti√°n Aballay L.
    url: https://www.linkedin.com/in/bastianaballay/
date: "2022-01-19"
bibliography: clase-03.bib
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: true
    highlight: tango
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r packages, include=FALSE}
suppressPackageStartupMessages(library(tidyverse))

library(xaringanExtra)
xaringanExtra::use_panelset()
```

En la [Clase 2](https://hapst.netlify.app/posts/clase-02/) revisamos los aspectos te√≥ricos b√°sicos
que nos permiten caracterizar a las series de tiempo.

En esta clase revisaremos las series de tiempo desde una perspectiva pr√°ctica,
estableciendo los requerimientos necesarios para lograr manipularlas, agregarlas y
pronosticarlas usando ecosistemas de `R`. Luego de esta clase podr√°s:

+ Conocer los requerimientos t√©cnicos (*packages*) para trabajar con series de tiempo en `R`
+ Manipular y agregar series de tiempo
+ Entender el proceso de evaluaci√≥n de pron√≥sticos a trav√©s del tiempo
+ Definir indicadores de desempe√±o adecuados para evaluar modelos de pron√≥stico
+ Entender la importancia de establecer una modelo ingenuo como pron√≥stico inicial
+ Generar caracter√≠sticas para modelos de pron√≥stico a partir del √≠ndice temporal asociado a la serie
+ Modelar series de tiempo utilizando Regresi√≥n Lineal 

# Objetos de R para Series de Tiempo

Desde la perspectiva program√°tica, una serie de tiempo es una serie de observaciones
cuyo principal atributo es poseer un *√≠ndice temporal* (*timestamp*) asociado a cada
una de ellas. Dicho √≠ndice puede tomar la forma de un objeto de `R` tipo `date`,
un objeto temporal u otro formato dependiendo de la frecuencia de la serie. La 
generaci√≥n de dicho √≠ndice a partir de datos *raw* no es trivial y en general
requerir√° de un preprocesamiento o formateo de los datos a un formato de series de tiempo.
Es por ello que conocer los ecosistemas que permitan al pracicante ser capaz de trabajar con 
per√≠odos temporales y fechas se vuelve esencial.

## base üßìüë¥

### Date

En ciertos lugares existen diferentes convenciones para trabajar con fechas (*dates*). 

```{r dates, echo = FALSE, fig.cap = "Fuente: [Date Format in the United States](https://iso.mit.edu/americanisms/date-format-in-the-united-states/)"}
knitr::include_graphics("https://iso.mit.edu/wp-content/uploads/2020/01/am_dateformat.gif")
```

Sin embargo, existe un est√°ndar global (`ISO 8601 YYYY-MM-DD`) que especifica la 
manera correcta para lidiar con fechas evitando toda confusi√≥n: ordenando los 
componentes de manera decreciente (a√±os &rarr; meses &rarr; d√≠as). Cada valor
posee una cantidad fija de digitos, por lo que es necesario rellenar con ceros
algunos meses (i.e Septiembre: mes 9 &rarr; `09`). La mejor manera de indicar a `R`
que nos encontramos trabajando con fechas es declararlo de manera expl√≠cita
utilizando el m√©todo `as.Date` sobre un string con una fecha en formato ISO.

```{r}
2021-11-08 # No es una fecha
str("2021-11-08") # String con una fecha
as.Date("2021-11-08") # Fecha
str(as.Date("2021-11-08")) # Estructura objeto Date
```

Tras bambalinas, los objetos tipo `Date` son almacenados como los d√≠as 
transcurridos desde `1970-01-01`, lo que significa que es posible llevar a cabo
comparaciones matem√°ticas con ellas:

```{r}
# ¬øEs hoy mayor que ayer?
as.Date("2021-11-08") > as.Date("2021-11-07")
```

adema≈õ de restar unidades de tiempo,

```{r}
# ¬øQue fecha era hace un dia (una unidad de tiempo) atras?
as.Date("2021-11-08") - 1
```

y calcular diferencias entre fechas.

```{r}
# ¬øCuantos dias han pasado desde la ultima clase?
as.Date("2021-11-08") - as.Date("2021-10-25")
```

Si disponemos de fechas, podemos hacer uso de la potencia de `R` para graficar con `r-base`: 

```{r}
x <- c(
  as.Date("2021-11-08"),
  as.Date("2021-10-08"),
  as.Date("2021-09-08"),
  as.Date("2021-08-08"),
  as.Date("2021-07-08")
)

set.seed(2021)
y <- rnorm(5)

plot(x, y, type = "b")
```

o bien con `ggplot2`  

```{r}
ggplot() +
  geom_line(aes(x = x, y = y)) +
  geom_point(aes(x = x, y = y))
```

Adem√°s, podemos obtener la fecha del sistema en el que nos encontremos trabajando con
`Sys.Date()`

```{r}
Sys.Date()
```

### Time

Continuando la idea de `ISO 8601`, para incorporar un per√≠odo en espec√≠fico continuamos
definiendo elementos de manera decreciente: `HH:MM:SS`, donde las horas poseen dos
d√≠gitos fijos (`00` - `24`) as√≠ como tambi√©n los minutos (`00` - `59`) y segundos, pudiendo existir sin separador o con `:`.

Existen dos tipos de fechas en `R`:

* `POSIXlt`: lista con componentes nombrados
* `POSIXct`: segundos desde `1970-01-01 00:00:00`, la coersi√≥n desde un string
se lleva cabo mediante `as.POSIXct()`

Verifiquemos la estructura de un objeto `POSIXct`

```{r}
lesson3_date <- as.POSIXct("2021-11-08 19:00:00")
str(lesson3_date)
```

### Timezone

La `ISO 8601` tambi√©n permite especificar zonas, asumiendose zona local ante la 
ausencia de su definici√≥n:

```{r}
# Coordinated Universal Time
as.POSIXct("2021-11-08 19:00:00", tz = "UTC")
```

La operatoria aritm√©tica revisada con datos del tipo `Date` se extiende a los 
datos tipo `POSIXct`.

## lubridate ‚è∞

A medida que los requerimientos de manipulaci√≥n de datos han evolucionado a trav√©s
del tiempo, tambi√©n lo han hecho los paquetes con los cuales se abordan dichos
desaf√≠os. `lubridate` es un paquete de `R` que permite trabajar de manera f√°cil
con tiempos y fechas^[Adem√°s de format parte del [`tidyverse`](https://lubridate.tidyverse.org/)].

Veamos como trabajar fechas a partir de distintos formatos:

```{r}
lubridate::ymd("2021-11-08") # YYYY-MM-DD
lubridate::dmy("08/11/2021") # DD/MM/YYYY
lubridate::parse_date_time("Sep 11th, 2021", order = c("mdy"))
lubridate::parse_date_time("11th Sep 2021", order = c("dmy"))
```

Y obtener informaci√≥n de inter√©s como:

```{r}
# Anio
lubridate::year("2021-11-08")

# Mes
lubridate::month("2021-11-08")

# Mes con etiqueta
lubridate::month("2021-11-08", label = TRUE) # factor!

# Dia
lubridate::day("2021-11-08")

# Dia de la semana
lubridate::wday("2021-11-08", label = TRUE) # factor!

# Dia del anio
lubridate::yday("2021-11-08")
```

```{r}
# Fecha-Hora-Minuto
lubridate::ymd_hm("2021-11-08 07:00pm")

# Hora
lubridate::hour("2021-11-08 07:00pm")

# Minuto
lubridate::minute("2021-11-08 07:00pm")
```

y la fecha en una zona en particular:

```{r}
# Chile because of reasons
lubridate::with_tz("2021-11-08", "America/Santiago") 
```

Adem√°s, podemos crear fechas con los m√©todos del tipo `make_date*()` 

```{r}
# Fecha
lubridate::make_date(year = 2021L, month = 11L, day = 8L)

# Tiempo
lubridate::make_datetime(year = 2021L, month = 11L, day = 8L, hour = 7L, min = 0L)
```

y obtener datos adicionales 

```{r}
# Trimestre
lubridate::quarter("2021-11-08 07:00pm")

# Semestre
lubridate::semester("2021-11-08 07:00pm")

# Anio bisiesto
lubridate::leap_year("2021-11-08 07:00pm")
```

Podemos restar fechas utilizando `difftime()`

```{r}
difftime("2021-11-08", "2021-10-25", units = "weeks")
```

y obtener el ahora

```{r}
lubridate::now()
```

as√≠ como tambi√©n la fecha de hoy.

```{r}
lubridate::today()
```

En una semana m√°s

```{r}
lubridate::today() + lubridate::days(7)
```

En particular, cabe destacar dos definiciones en `lubridate` para intervalos 
temporales

+ `period`: per√≠odo o concepto humano de intervalo temporal. Una fecha (*datetime*) + un per√≠odo de un d√≠a = mismo momento en la fecha siguiente.
+ `duration`: duraci√≥n o concepto *cronometrado* del tiempo. Una fecha + un per√≠odo de un d√≠a = fecha + 86400 segundos.

Veamos la diferencia

```{r}
lubridate::days(x = 7)
lubridate::ddays(7)
```


![Lubridate CheatSheet](https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf){width=100% height=400}

## `ts()` üíä

Supongamos que tenemos los siguientes datos:

| A√±o  | Observaci√≥n | 
| ---  | ----------- |
| 2017 | 20          |
| 2018 | 30          |
| 2019 | 60          |
| 2020 | 40          |
| 2021 | 25          |

Podemos almacenar una serie de tiempo en un objeto tipo `ts` utilizando la 
funci√≥n `ts()`.

```{r}
set.seed(2021)
y <- ts(rnorm(5), start=2017)
```

Es posible asociar observaciones que poseen una frecuencia mayor que la anual utilizando el argumento `frequency`

```{r}
set.seed(2021)
y <- ts(rnorm(12*5), start=2017, frequency = 12)
```

En este caso, las frecuencias se definen como sigue

| Dato       | Frecuencia  | 
| ---------  | ----------- |
| Anual      |     1       |
| Trimestral |     4       |
| Mensual    |     12      |
| Semanal    |     52^[En un a√±o hay $365.25/7 = 52.18$ semanas en promedio, sin embargo, los objetos `ts` requieren de frecuencia dictadas por n√∫meros enteros.] |

> ¬øQu√© ocurre si la frecuencia de mis observaciones es mayor a la semanal?

En el caso de utilizar objetos `ts`, es necesario decidir que frecuencia
es m√°s representativa de la serie^[[fpp2: `ts` objects](https://otexts.com/fpp2/ts-objects.html)] considerando efectos como la estacionalidad (en
caso de que aplique).

## `xts()` y `zoo()` üíäüíä

El paquete `xts` (*eXtensible time series*) busca ofrecer un formato flexible y poderoso para trabajar
con series de tiempo. Un objeto `xts` es un objeto tipo `zoo` (un √≠ndice + una matriz) extendido, donde 
cada fila corresponde a una observaci√≥n en el tiempo.

```{r}
x <- matrix(1:4, ncol = 2, nrow = 2)
idx <- as.Date(c("2021-10-01","2021-11-01"))
(x_xts <- xts::xts(x = x, order.by = idx))
```

Un aspecto relevante a notar es que el √≠ndice debe ser creciente en el tiempo, dejando las observaciones m√°s
recientes al final de la estructura de datos. Si se otorga un vector no ordenado, `xts` ordenar√° seg√∫n el √≠ndice para asegurarse de que los datos est√©n apropiadamente ordenados. Si te fijas, un objeto `xts` parece poseer `rownames`, sin embargo, dichos valores corresponden al √≠ndice asociado a la serie (`index`). `xts` posee comportamientos especiales que incluyen: sus valores son matrices asociadas a fechas por cada observaci√≥n, subconjuntos de los datos mantienen la forma matricial y adem√°s sus atributos son preservados. 

En el caso de necesitar deconstruir un objeto `xts`, los m√©todos `coredata()` e `index()` nos permiten obtener sus componentes internos

```{r}
zoo::coredata(x_xts, fmt = FALSE)
```

```{r}
zoo::index(x_xts, fmt = FALSE)
```

## `tsibble()` üíäüíäüíä

El paquete `tsibble`^[Hyndman et al: [https://tsibble.tidyverts.org/](https://tsibble.tidyverts.org/)] provee una infraestructura para datos temporales que adopta los principios de los datos `tidy`, siendo un objeto orientado a datos y modelos. Algunos aspectos importantes de los datos tipo `tsibble` son los siguientes:

1. `Index` es una variable con un orden inherente del pasado al presente
2. `Key` es un conjunto de variables que define unidades observacionales en el tiempo
3. Cada observaci√≥n debe ser unicamente identificada por un `index` y su `key`
4. Cada unidad observacional debe ser medida bajo un intervalo com√∫n (si est√°n regularmente espaciadas).

```{r}
# Ejemplo de la documentacion de tsibble
weather <- nycflights13::weather %>% 
  select(origin, time_hour, temp, humid, precip)
weather_tsbl <- tsibble::as_tsibble(weather, key = origin, index = time_hour)
weather_tsbl %>% rmarkdown::paged_table()
```

Los objetos `tsibble` extienden a los data frames (`tibble`) introduciendo una estructura temporal que facilita el almacenamiento de m√∫ltiples series de tiempo en un s√≥lo objeto, permitiendo aplicar funciones
de `dplyr` como `mutate()`, `filter()`, `select()` y `summarize()` a los datos almacenados.
 
## `timetk()` üíäüíäüíäüíäüöÄ

Tal como hemos visto, existen *muchos* paquetes de `R` para trabajar con series de tiempo. Uno de los √∫ltimos ecosistemas desarrollados con gran √©xito es `modeltime`^[[Matt Dancho's modeltime](https://business-science.github.io/modeltime/)] que incluye paquete `timetk`. Podemos revisar una tabla comparativa de las virtudes de `timetk` en el siguiente [enlace](https://business-science.github.io/timetk/index.html#package-functionality).

Revisemos algunas de las funcionalidades que otorga `timetk` para manipular series de tiempo^[Puedes encontrar este ejemplo y otras vi√±etas en la documentaci√≥n de [timetk](https://business-science.github.io/timetk/articles/TK07_Time_Series_Data_Wrangling.html)]

```{r}
tidyquant::FANG %>% rmarkdown::paged_table()
```

Podemos hacer facilmente gr√°ficos de series de tiempo

```{r}
tidyquant::FANG %>%
  group_by(symbol) %>%
  timetk::plot_time_series(date, adjusted, .facet_ncol = 2, .interactive = TRUE)
```

Resumir datos a trav√©s del tiempo

```{r}
tidyquant::FANG %>%
  group_by(symbol) %>%
  timetk::summarise_by_time(
    date, .by = "quarter",
    volume = tidyquant::SUM(volume)
  ) %>%
  timetk::plot_time_series(date, volume, .facet_ncol = 2, .interactive = TRUE, .y_intercept = 0)
```

y suavizar (entre otras funcionalidades) series de tiempo:

```{r}
tidyquant::FANG %>%
  group_by(symbol) %>%
  timetk::summarise_by_time(
    date, .by = "month",
    adjusted = tidyquant::FIRST(adjusted)
  ) %>%
  timetk::plot_time_series(date, adjusted, .facet_ncol = 2, .interactive = TRUE)
```

> ¬øEntonces qu√© paquete debo utilizar? ü§î^[A la fecha (2021-11-08), `timetk` se posiciona como uno de los mejores paquetes para manipulaci√≥n y modelamiento de series de tiempo. Presenta la mayor cantidad de funcionalidades y `wrappers` en comparaci√≥n a otros paquetes. El ecosistema de Matt Dancho (`modeltime`) est√° siendo extendido por otros colaboradores que han agregado m√°s modelos como por ejemplo: [`garchmodels`](https://albertoalmuinha.github.io/garchmodels/), [`bayesmodels`](https://albertoalmuinha.github.io/bayesmodels/index.html) y [`boostime`](https://albertoalmuinha.github.io/boostime/index.html). Sin embargo, [esta imagen](https://www.explainxkcd.com/wiki/images/d/d7/dependency.png) plantea bastantes desaf√≠os en relaci√≥n a la mantenci√≥n de soluciones de este tipo. ¬øRecomendaci√≥n? ¬°Aprender todos los formatos y saber moverse de uno a otro!üìñ]. 

# Evaluaci√≥n de pron√≥sticos üìè

## Set de entrenamiento y test üî™

La precisi√≥n de un pron√≥stico s√≥lo puede ser determinada considerando qu√© tan 
bien se desempe√±an los pron√≥sticos generados en datos nuevos que no han sido 
utilizados para ajustar el modelo (@Hyndman2021-hc). As√≠, al igual que como
se eval√∫an los modelos de Machine Learning, es una pr√°ctica com√∫n separar
los datos disponibles en dos conjuntos, un conjunto de ajuste o *entrenamiento*
(*training set*)^[a.k.a. *in-sample data*] y otro de evaluaci√≥n 
(*test set*)^[a.k.a. *out-sample data*, *hold-out set*], 
donde los datos de entrenamiento son utilizados para estimar los par√°metros de cualquier 
m√©todo de pron√≥stico y los datos de evaluaci√≥n son utilizados para determinar su precisi√≥n. 
Dado que los datos de evaluaci√≥n no son utilizados en el proceso de elaboraci√≥n
de los pron√≥sticos, √©stos nos permiten obtener un indicador confiable de qu√© tan
bien puede pronosticar un modelo los datos nuevos. 

<aside>
<p>Training Set</p>
<p>Test Set</p>
</aside>

Al momento de evaluar el desempe√±o de modelos de pron√≥stico es necesario
distinguir entre un *pron√≥stico* (*forecast*) o *valor predicho* (*predicted value*)
de $y_t$, realizado en alg√∫n per√≠odo previo, por ejemplo $t-\tau$, y un
*valor ajustado* (*fitted value*) de $y_t$, que ha resultado de estimar los par√°metros
de un modelo de series de tiempo en datos hist√≥ricos, generando *residuales*.

El m√©todo m√°s com√∫n para evaluar el √©xito de un pron√≥stico para predecir los valores
reales es utilizar m√©tricas de precisi√≥n o error. Aqu√≠ *error* no debe entenderse
como una equivocaci√≥n, sino como la parte impredecible de una observaci√≥n.
La selecci√≥n de la m√©trica espec√≠fica de error depender√° de los objetivos de 
pron√≥stico de que se tengan.

<aside>
Error de pron√≥stico
</aside>

El tama√±o del set de evaluaci√≥n depende de qu√© tanta informaci√≥n se posea y qu√©
tan adelante se quiera pronosticar. Es ideal que el test set tenga al menos
el largo del horizonte de pron√≥stico m√°ximo requerido.

Algunas observaciones a considerar

+ Un modelo que se ajusta bien a los datos de entrenamiento no necesariamente
pronosticar√° bien.
+ Siempre es posible obtener un ajuste perfecto usando un modelo con una cantidad
de par√°metros suficiente^[Por ejemplo, redes neuronales]
+ *Sobreajustarse* (*over-fit*) un modelo a los datos es tan malo como fallar en
identificar los patrones sistem√°ticos en ellos.

## Validaci√≥n Cruzada para Series de Tiempo (TSCV) üìù

Uno de los aspectos m√°s relevantes del proceso de pron√≥stico planteado en la [Clase 01](https://hapst.netlify.app/posts/clase-01/index.html#forecastingprocess) fue la validaci√≥n de los modelos. En particular mencionamos la *validaci√≥n cruzada para series de tiempo*^[[fpp3: Time series cross-validation](https://otexts.com/fpp3/tscv.html)] ^[[caret: Data Splitting for Time Series](https://topepo.github.io/caret/data-splitting.html#time)].

La validaci√≥n cruzada de series de tiempo (a.k.a. *backtesting*) puede entenderse como una versi√≥n avanzada de la metodolog√≠a de validaci√≥n *single out-of-sample* utilizada para validar modelos de machine learning^[Un muestreo aleatorio de una serie de tiempo probablemente no sea la mejor idea para muestrear datos que presentan dependencias temporales.¬°Ya sabemos que el orden temporal s√≠ importa!] . Se basa en el uso de una *ventana rodante* (*rolling window*) para particionar la serie en m√∫ltiples pares de entrenamiento-evaluaci√≥n. En general el proceso de validaci√≥n cruzada involucra la *creaci√≥n de las particiones* mencionadas, el *entrenamiento o ajuste de un modelo* con los datos de entrenamiento de cada partici√≥n, la *evaluaci√≥n de su desempe√±o* por partici√≥n con los datos de evaluaci√≥n de cada partici√≥n y la *evaluaci√≥n del modelo* a nivel de precisi√≥n, escalabilidad y estabilidad basado en las m√©tricas de desempe√±o obtenidas en los datos de evaluaci√≥n por partici√≥n.

Como resultado del proceso anterior es posible generar un pron√≥stico final para revisar si se cumplen los criterios requeridos para su validez o bien aplicar ajustes adicionales y optimizar el modelo repitiendo el proceso de evaluaci√≥n. Es usual considerar un modelo como estable si al examinar su desempe√±o en los datos de evaluaci√≥n a trav√©s de las particiones, la distribuci√≥n del error es estrecha, de este modo, los errores obtenidos en los verdaderos valores pronosticados deber√≠an estar en el mismo rango de los errores de cada partici√≥n^[Asumiendo que no hay comportamientos anormales que impacten las m√©tricas de desempe√±o consideradas.].

Revisemos nuevamente el esquema de validaci√≥n considerado en `caret`:

```{r tscv, echo = FALSE, fig.cap = "Fuente: [Caret Package - Max Kuhn](https://topepo.github.io/caret/)"}
knitr::include_graphics("https://topepo.github.io/caret/splitting/Split_time-1.svg")
```

De manera gen√©rica^[Independiente del paquete utilizado], los par√°metros a considerar para llevar a cabo validaci√≥n cruzada para series de tiempo son los siguientes:

+ Largo de las particiones de entrenamiento o tama√±o de ventana. Existen dos tipos
  + Ventana expansiva (`expanding window`): el tama√±o de la partici√≥n de entrenamiento crece a trav√©s de las ventanas temporales^[V√©ase fila inferior de la Figura \@ref(fig:tscv)]. 
  + Ventana deslizante (`sliding window`): el tama√±o de la partici√≥n de entrenamiento se mantiene fijo a trav√©s de las ventanas temporales^[V√©ase fila superior de la  Figura \@ref(fig:tscv)]
+ Largo de las particiones de evaluaci√≥n u horizonte de pron√≥stico.
+ Espacio^[de ser requerido] entre particiones de entrenamiento y evaluaci√≥n
+ Cantidad de particiones

El m√©todo de la ventana expansiva es √∫til cuando la serie posee fuertes patrones estacionales y tendencia estable, pues las primeras observaciones podr√≠an poseen informaci√≥n relevante que pueda ser utilizada por el modelo. La principal desventaja del m√©todo radica en que cada partici√≥n tendr√° una cantidad diferente de datos de entrenamiento y los modelos aprenden mejor con mayor cantidad de datos^[No es sorprendente notar que el rendimiento del modelo en las √∫ltimas particiones sea mejor que el de las primeras.].

El sesgo anterior no est√° presente cuando se utiliza el m√©todo de la ventana deslizante, dado que todas las particiones poseen el mismo largo. Este m√©todo es recomendable cuando existen variaciones irregulares o cuando el poder predictivo est√° relacionado a la historia m√°s reciente.

> Ô∏èüö® Los beneficios de monitorear la estabilidad de un modelo conllevan un costo: la validaci√≥n cruzada de series de tiempo^[Y como veremos m√°s adelante, la optimizaci√≥n de hiper-par√°metros de modelo...] es un proceso computacionalmente costoso^[Pero por otro lado, sabemos que la validaci√≥n cruzada es un proceso [vergonzosamente paralelizable](https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html#embarrassing-parallelism) y actualmente tenemos a disposici√≥n alternativas de c√≥mputo en la nubeüíÖ ....].

## Modelos benchmark (naive) üìê

En muchas organizaciones, la elaboraci√≥n de pron√≥sticos es llevada a cabo utilizando reglas y conocimiento de negocio. Este favorable escenario nos puede servir para establecer una situaci√≥n base, benchmark o situaci√≥n "sin proyecto". Cualquier m√©todo de pron√≥stico que no provea de mejoras en rendimiento por sobre dichos escenarios base no ser√° de valor para la organizaci√≥n y lo m√°s l√≥gico es que sea descartado. El caso contrario ocurre cuando no se dispone de un pron√≥stico preliminar o la tarea de pron√≥stico se encuentra siendo abordada por vez primera. En esta situaci√≥n, antes de modelar y llevar a cabo esfuerzos de an√°lisis y pron√≥stico de series de tiempo, es recomendable establecer una l√≠nea base sobre la cual construir soluciones m√°s complejas^[Lamentablemente, este no es un curso de *problem solving* üôÅ. ¬°La pr√°ctica le ense√±ar√° a no matar moscas con tanques! üê∑].

Algunos m√©todos de pron√≥stico pueden ser extremadamente simples y efectivos. Algunos m√©todos a considerar antes de realizar cualquier esfuerzo de pron√≥stico son los siguientes:

1. Pronosticar con el promedio hist√≥rico (*mean method*). Todos los valores futuros son iguales a la media de los datos hist√≥ricos
2. Definir como pron√≥stico el valor asociado a la √∫ltima observaci√≥n. En este caso hablamos de un m√©todo ingenuo (*na√Øve method*)^[Funciona sorprendentemente bien en series de tiempo financieras. Tambi√©n son llamadas *caminatas aleatorias* (*random walk*), como veremos m√°s adelante.].
3. Definir  como pron√≥stico el valor asociada a la √∫ltima observaci√≥n con estacionalidad similar. En este caso, hacemos uso del patr√≥n estacional predominante en los datos, por ejemplo, asociando un pron√≥stico para el pr√≥ximo mes equivalente al valor obtenido en la misma √©poca del a√±o pasado.

Veamos como podemos ajustar modelos ingenuos utilizando `modeltime`:

1. Cargamos librer√≠as y datos

```{r}
library(dplyr)
library(parsnip)
library(rsample)
library(timetk)
library(modeltime)
# Datos competencia M4
m750 <- m4_monthly %>% filter(id == "M750")
m750 %>% rmarkdown::paged_table()
```

2. Partici√≥n en conjuntos de entrenamiento y evaluaci√≥n

```{r}
# Particionamos los datos en proporcion 80/20
splits <- initial_time_split(m750, prop = 0.8)
splits
```

3. Definici√≥n de especificaci√≥n de modelos

```{r}
# Naive model ----
# Model Spec (parsnip)
model_spec_naive <- naive_reg(
  id = "id"
) %>%
  set_engine("naive")

model_spec_naive

# Seasonal Naive model ----
# Model Spec (parsnip)
model_spec_snaive <- naive_reg(
  id = "id",
  seasonal_period = 12
) %>%
  set_engine("snaive")

model_spec_snaive
```

4. Ajuste (entrenamiento) de modelos

```{r}
# Ajuste ----
# Fit Spec
model_fit_snaive <- model_spec_snaive %>%
  fit(log(value) ~ date + id, data = training(splits))
model_fit_snaive

model_fit_naive <- model_spec_naive %>%
  fit(log(value) ~ date + id, data = training(splits))
model_fit_naive
```

5. Establecimiento de tabla de modelos^[Requerida por ecosistema `modeltime`]

```{r}
# ---- MODELTIME TABLE ----
# Tibble con modelos ajustados
models_tbl <- modeltime_table(
  model_fit_naive,
  model_fit_snaive
)
```

6. Validaci√≥n de modelo en datos de evaluaci√≥n

```{r}
# Validacion en test
calibration_tbl <- models_tbl %>%
  # Calibracion en datos de test para evaluacion de rendimiento
  modeltime_calibrate(new_data = testing(splits)) %>%
  # Pronostico en datos de test
  modeltime_forecast(
    new_data    = testing(splits),
    actual_data = m750
  )
```

7. Gr√°fico de pron√≥stico

```{r}
calibration_tbl %>% 
# Grafico pronosticos
  plot_modeltime_forecast(.interactive = TRUE)
```

## M√©tricas de desempe√±o üíØ

### MAE

En el *error absoluto medio* (*Mean Absolute Error* (MAE)), el error de pron√≥stico
est√° en la misma escala que los datos originales. Debido a lo anterior, no puede
ser utilizado para comparar desempe√±o entre series que involucren distintas unidades
de medida. Un m√©todo de pron√≥stico que minimice el MAE conducir√° a pronosticos
de la mediana. Este m√©todo no es sensible a outliers.

$$MAE = \frac{1}{T}\sum_{t=1}^{T}\left|y_{t}-\hat{y}_{t}\right|$$

### MSE

El error cuadr√°tico medio (*Mean Squared Error* (MSE)) cuantifica la distancia al 
cuadrado promedio entre los valores reales y los pronosticados. 
El efecto de elevar al cuadrado previene que los valores negativos
y positivos se cancelen entre s√≠, penalizando el error si es muy elevado.
Un m√©todo de pron√≥stico que minimice el MSE conducir√° a pronosticos
de la media.

$$MSE = \frac{1}{T}\sum_{t=1}^{T}(y_t - \hat{y}_t)^2$$

### RMSE

Similar a MSE, en las unidades de las observaciones.

$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{T}\sum_{t=1}^{T}(y_t - \hat{y}_t)^2}$$

### MAPE

El error porcentual absoluto medio (*Mean Absolute Percentage Error* (MAPE)) es una
de las m√©tricas m√°s f√°ciles de comparar y comunicar con interlocutores no-t√©cnicos
dado que representa un porcentaje. Los errores porcentuales poseen la ventaja de 
no tener unidades y son utilizados para comparar el desempe√±o de un modelo
de pron√≥stico entre datasets. Sin embargo, poseen la desventaja de ser infintos
o indefinidos si $y_t = 0$ para cualquier periodo de inter√©s $t$, adem√°s de tener
valores extremos cuando $y_t$ es cercano a cero. Adem√°s, poseen la desventaja
de penalizar errores negativos m√°s que los positivos, lo que condujo a la 
elaboraci√≥n de otra m√©trica porcentual llamada sMAPE (*symmetric MAPE*), usado
en la competencia M3.

$$MAPE = \frac{1}{T}\sum _{t=1}^{T}\bigg(\frac{|y_{t}-\hat{y}_{t}|}{y_{t}}\bigg)\times100$$

### SMAPE

$$SMAPE = {\frac{1}{T}\sum _{t=1}^{T}\bigg(\frac{2|y_{t}‚àí\hat{y}_{t}|}{y_{t}+\hat{y}_{t}}\bigg)\times 100}$$ 


### $R^{2}$

$$R^{2} = {1-{\frac {\sum _{t=1}^{T}\left(y_{t}-\hat{y}_{t}\right)}{\sum _{i=1}^{T}\left(y_{t}-\bar{y}_{t}\right)}}}$$

Obtengamos las m√©tricas de rendimiento de los modelos ingenuos revisados anteriormente

```{r}
# Metricas de rendimiento
models_tbl %>%
  # Calibracion en datos de test para evaluacion de rendimiento
  modeltime_calibrate(new_data = testing(splits)) %>%
  modeltime_accuracy() %>%
  table_modeltime_accuracy(
    .interactive = TRUE
  )
```

## Evaluaci√≥n de desempe√±o en R üìö

Podemos encontrar las m√©tricas revisadas anteriormente en los siguientes
paquetes:

+ [`Metrics`](https://cran.r-project.org/web/packages/Metrics/index.html)
+ [`yardstick`](https://yardstick.tidymodels.org/) 

# Regresi√≥n Lineal para pron√≥stico de series de tiempo üìà‚ú®

La *regresi√≥n lineal* es uno de los m√©todos m√°s utilizados para identificar y cuantificar la relaci√≥n entre una variable dependiente^[*output*, *end√≥gena*,*variable explicada*,*pron√≥stico*, "$y$"] y una √∫nica^[Regresi√≥n Lineal Univariada] o m√∫ltiples^[Regresi√≥n Lineal Multivariada] variables independientes^[*input*, *ex√≥gena*,*variable explicativa*, *predictora*, "$x$"]. 

Consideremos un modelo de regresi√≥n que permita una relaci√≥n lineal entre el pron√≥stico $y$ y un √∫nico predictor $x$. El modelo de *regresi√≥n lineal simple* se puede escribir como

$$y_t = \beta_0 + \beta_{1}x_{t} + \epsilon_t$$

En este caso, serie de tiempo a predecir es $y_t$, $\beta_0$ es el *intercepto*^[Valor constante que representa la media del valor esperado de $y_t$ cuando $x_t = 0$], $\beta_1$ es la *pendiente* que representa el cambio promedio de $y$ ante el incremento unitario de $x$, y $\varepsilon_t$ es una serie de tiempo de *residuos*.

En el caso de la *regresi√≥n lineal m√∫ltiple*, se tiene m√°s de una variable explicativa:

$$y_t = \beta_0 + \beta_{1}x_{1,t} + \beta_{2}x_{2,t} + \dots + \beta_{k}x_{k,t} +  \epsilon_t$$
Aqu√≠, el modelo s√≥lo incluye relaciones contempor√°neas entre los regresores y la variable respuesta, por lo que hablamos de un *modelo  de regresi√≥n est√°tico*. Dichos modelos son apropiados cuando el valor esperado de la respuesta cambia inmediatamente cuando cambia el valor de una variable explicativa. Cada coeficiente de regresi√≥n $\beta$ modela el cambio instant√°neo en el valor esperado condicional de la variable $y_t$ ante el cambio unitario de $x_{k,t}$, dejando todas las dem√°s preditores constantes.  

Un *modelo de regresi√≥n din√°mico*^[El t√©rmino tambien es utilizado en la literatura para describir de manera general a los modelos de regresi√≥n con errores autocorrelacionados en el tiempo] incorpora relaciones entre valores actuales y rezagados de las variables independientes, lo que significa que la variable respuesta podr√≠a cambiar *luego* de un cambio en los valores de las variables explicativas.

$$\begin{aligned} 
y_t = \beta_0  & + \beta_{10}x_{1,t} + \beta_{11}x_{1,t-1} + ... + \beta_{1m}x_{1,t-m} \\
& + \beta_{20}x_{2,t} + \beta_{21}x_{2,t-1} + ... + \beta_{2m}x_{2,t-m} \\
& + \dots \\
& + \beta_{k0}x_{k,t} + \beta_{k1}x_{k,t-1} + ... + \beta_{km}x_{2,t-m} \\
& + \epsilon_t \\
\end{aligned}$$ 

## Caso Aplicado

A continuaci√≥n veremos c√≥mo podemos analizar una serie de tiempo con R y ajustar un modelo de regresi√≥n lineal como aproximaci√≥n para mejorar una aproximaci√≥n ingenua. Para ello utilizaremos el dataset `USgas` que contiene la [demanda de gas natural](https://cran.r-project.org/web/packages/USgas/index.html) en US por estado y a nivel pa√≠s.

```{r}
library(USgas)
 
# The us_monthly dataset provides a monthly time series, 
# representing the demand for natural gas in the US between 2001 and 2020:
data("us_monthly")
head(us_monthly)
```

+ Particionamos los datos en proporcion `80/20`

```{r}
splits <- us_monthly %>% 
  timetk::tk_tbl() %>% 
  initial_time_split(prop = 0.8)
```

+ Graficamos los datos de entrenamiento

```{r}
training(splits) %>% 
  timetk::plot_time_series(
    .date_var = date,
    .value = y,
    .smooth = FALSE,
    .interactive = TRUE
  )
```

+ Realizamos una descomposici√≥n en componentes de tendencia y estacionalidad

```{r}
training(splits) %>% 
  plot_stl_diagnostics(
    .date_var = date, 
    .value = y,
    .feature_set = c("observed", "season", "trend", "remainder"),
    .interactive = TRUE)
```

+ Ajustamos la tendencia mediante regresi√≥n lineal

```{r}
training(splits) %>% 
  plot_time_series_regression(
    .date_var     = date,
    .formula      = y ~ as.numeric(date),
    .show_summary = TRUE,
    .facet_ncol   = 2,
    .interactive  = FALSE
  )
```

+ Ajustamos la estacionalidad mediante regresi√≥n lineal

```{r}
training(splits) %>% 
  plot_time_series_regression(
    .date_var     = date,
    .formula      = y ~ lubridate::month(date, label = TRUE),
    .show_summary = TRUE,
    .facet_ncol   = 2,
    .interactive  = FALSE
  )
```

+ Ajustamos la tendencia y estacionalidad mediante regresi√≥n lineal

```{r}
training(splits) %>% 
  plot_time_series_regression(
    .date_var     = date,
    .formula      = y ~ as.numeric(date) + lubridate::month(date, label = TRUE),
    .show_summary = TRUE,
    .facet_ncol   = 2,
    .interactive  = FALSE
  )
```

+ Ajustamos la tendencia de manera lineal y polinomial, adem√°s de la estacionalidad mediante regresi√≥n lineal

```{r}
training(splits)  %>% 
  plot_time_series_regression(
    .date_var     = date,
    .formula      = y ~ as.numeric(date) + I(as.numeric(date)^2) + lubridate::month(date, label = TRUE),
    .show_summary = TRUE,
    .facet_ncol   = 2,
    .interactive  = FALSE
  )
```

+ Ya tenemos una propuesta de modelo, podemos evaluar su capacidad predictiva *out-sample*

```{r}
model_spec_lm <- linear_reg() %>%
  set_engine("lm")

model_fit_lm <- model_spec_lm %>%
  fit(
    y ~ as.numeric(date) + I(as.numeric(date) ^ 2) + lubridate::month(date, label = TRUE),
    data = training(splits)
  )
```

+ Y, por supuesto, establecer un punto de comparaci√≥n ingenuo

```{r}
model_spec_snaive <- naive_reg(seasonal_period = 12) %>%
  set_engine("snaive")

model_fit_snaive <- model_spec_snaive %>%
  fit(y ~ date , data = training(splits))
model_fit_snaive
```

+ Generamos la tabla de modelos^[Requerimiento de ecosistema `modeltime`] 

```{r}
models_tbl <- modeltime_table(
  model_fit_lm,
  model_fit_snaive
)
models_tbl
```

+ *Calibramos*^[Terminolog√≠a `modeltime` para ajuste y pron√≥stico de valores] los modelos en el set de evaluaci√≥n (test)

```{r}
calibration_tbl <- models_tbl %>%
  # Calibracion en datos de test para evaluacion de rendimiento
  modeltime_calibrate(new_data = testing(splits)) %>%
  # Pronostico en datos de test
  modeltime_forecast(
    new_data    = testing(splits),
    actual_data = us_monthly
  )
calibration_tbl
```

+ Graficamos los pron√≥sticos para comparar visualmente

```{r}
calibration_tbl %>% 
  # Grafico pronosticos
  plot_modeltime_forecast(.interactive = TRUE)
```

+ Revisamos el desempe√±o en datos de evaluaci√≥n

```{r}
models_tbl %>%
  # Calibracion en datos de test para evaluacion de rendimiento
  modeltime_calibrate(new_data = testing(splits)) %>%
  modeltime_accuracy() %>%
  table_modeltime_accuracy(
    .interactive = TRUE
  )
```


## An√°lisis de residuales üöØ

El an√°lisis de residuales permite analizar qu√© tan bien el modelo captura e identifica
los patrones de la serie. Adem√°s, podemos elaborar intervalos de confianza para los pron√≥sticos generados a partir de la distribuci√≥n de los residuales. Podemos definir a los residuales como la diferencia entre el valor real observado ($y_i$) y su correspondiente valor ajustado por el modelo ($\hat{y_i}$), para cada $i = 1, \dots, T$.

$$\epsilon_i = y_i - \hat{y_i}$$ 

Revisemos los conceptos anteriores aplicados a los modelos ajustados para `USgas`:

+ Generamos los residuales de entrenamiento

```{r}
residuals_tbl <- models_tbl %>%
  modeltime_calibrate(new_data = training(splits)) %>%
  modeltime_residuals()
```

+ Graficamos los residuales en el tiempo (entrenamiento)

```{r}
residuals_tbl %>%
  plot_modeltime_residuals(
    .interactive = TRUE,
    .y_intercept = 0,
    .y_intercept_color = "blue"
  )
```

+ Graficamos los funci√≥n de autocorrelaci√≥n de los residuales en el tiempo (entrenamiento)

```{r}
residuals_tbl %>%
  plot_modeltime_residuals(
    .interactive = TRUE,
    .type = "acf"
  )
```

+ Graficamos los estacionalidad (de existir) de los residuales en el tiempo (entrenamiento)

```{r}
residuals_tbl %>%
  plot_modeltime_residuals(
    .interactive = TRUE,
    .type = "seasonality"
  )
```

+ Obtenemos el error de pron√≥stico (test)

```{r}
forecast_error_tbl <- models_tbl %>%
  modeltime_calibrate(new_data = testing(splits)) %>%
  modeltime_residuals()
```

+ Graficamos el error de pron√≥stico en el tiempo (test)

```{r}
forecast_error_tbl %>%
  plot_modeltime_residuals(
    .interactive = TRUE,
    .y_intercept = 0,
    .y_intercept_color = "blue"
  )
```

+ Graficamos los funci√≥n de autocorrelaci√≥n del error en el tiempo (test)

```{r}
forecast_error_tbl %>%
  plot_modeltime_residuals(
    .interactive = TRUE,
    .type = "acf"
  )
```

+ Realizamos [tests estad√≠sticos](https://business-science.github.io/modeltime/reference/modeltime_residuals_test.html#examples) a los residuales (entrenamiento) 

```{r}
models_tbl %>% 
  filter(.model_id == 1) %>% 
  modeltime_calibrate(new_data = training(splits)) %>%
  modeltime_residuals() %>%
  modeltime_residuals_test()
```

+ **BONUS** üåÄ : generaci√≥n de caracter√≠sticas (variables) autom√°tica con `timetk`^[¬°Pr√≥ximas clases!] 

```{r}
training(splits) %>% 
  timetk::tk_augment_timeseries_signature(.date_var = date) %>% 
  timetk::tk_augment_fourier(date, .periods = 12, .K = 2) %>% 
  glimpse()
```

## Validacion Cruzada para series de tiempo

```{r}
library(modeltime.resample) # TSCV
library(tidymodels)

# Especificacion Regresion Lineal-
model_spec_lm <- linear_reg() %>%
  set_engine("lm")

# Se extienden los datos originales con registros a ser pronosticados
us_monthly_full <- us_monthly %>%
  timetk::tk_tbl() %>%
  # Horizonte de pronostico h = 12
  timetk::future_frame(.date_var = date,
                       .length_out = "12 months",
                       .bind_data = TRUE)

# Revision de datos a pronosticar en el mismo objeto
us_monthly_full %>%
  tail(15)

# Datos de entrenamiento
us_monthly_tbl <- us_monthly_full %>%
  filter(!is.na(y))

# Datos a pronosticar (fechas)
us_monthly_future_tbl <- us_monthly_full %>%
  filter(is.na(y))

# Cantidad de meses y anios para entrenar y validar
us_monthly_tbl %>%
  summarise(total_months = n_distinct(date)) %>%
  mutate(total_years = total_months / 12)

# Especificacion receta
# Forma funcional
recipe_spec <- recipes::recipe(y ~ date, data = us_monthly_full) %>%
  # Agrega Mes como variable categorica
  recipes::step_date(date, features = "month", ordinal = FALSE) %>%
  # Agrega tendencia lineal
  recipes::step_mutate(trend = as.numeric(date)) %>%
  # Agrega tendencia polinomial
  recipes::step_mutate(poly_trend = I(as.numeric(date)) ^ 2) %>%
  #recipes::step_normalize(date_num) %>%
  # Remueve la fecha para ajuste
  recipes::step_rm(date)

# Revisamos el eventual resultado de preprocesamiento
recipe_spec %>%
  prep() %>%
  juice() %>%
  tail(20)

# Se establece un workflow que incorpora la receta de preprocesamiento y la
# la especificacion del modelo a ajustar. El workflow se ajusta para
# establecer la forma funcional
wflw_fit_lm <- workflow() %>%
  add_recipe(recipe_spec) %>%
  add_model(model_spec_lm) %>%
  fit(us_monthly_full)

# Esquema de validacion cruzada
us_monthly_tscv <- us_monthly_tbl %>%
  timetk::time_series_cv(
    date_var    = date,
    initial     = 12 * 15,
    # 15 anios
    assess      = "12 months",
    # Evaluacion
    skip        = "12 months",
    # Desplazamiento de ventana rodante
    cumulative  = TRUE # Acumulacion de datos historicos
  )

# Distancia temporal ascendente en particiones (slices)
# Grafico de esquema de validacion cruzada
us_monthly_tscv %>%
  timetk::tk_time_series_cv_plan() %>%
  plot_time_series_cv_plan(date, y,
                           .facet_ncol = 2, .interactive = TRUE)

# Tabla de modelos (Workflow modeltime)
(models_tbl <- modeltime_table(wflw_fit_lm))

# Ajuste de modelo a distintas particiones
resamples_fitted <- models_tbl %>%
  modeltime.resample::modeltime_fit_resamples(resamples = us_monthly_tscv,
                                              control   = tune::control_resamples(verbose = TRUE))

# Desempenio de modelos a traves de particiones (TSCV)
resamples_fitted %>%
  plot_modeltime_resamples(
    .point_size  = 3,
    .point_alpha = 0.8,
    .interactive = FALSE
  )

# Evaluacion de capacidad predictiva promedio
resamples_fitted %>%
  modeltime_resample_accuracy(summary_fns = mean) %>%
  table_modeltime_accuracy(.interactive = FALSE)

# Pronostico Real
resamples_fitted %>%
  modeltime_forecast(new_data = us_monthly_future_tbl,
                     actual_data = us_monthly_full) %>%
  plot_modeltime_forecast(.interactive = TRUE)

# Grafico comparativo particiones 
# Try-hard: podria ser un feature request para el paquete
slice_plot <- resamples_fitted$.resample_results %>%
  pluck(1) %>%
  mutate(
    training_tbl = map(splits, training),
    testing_tbl = map(splits, testing)
  ) %>%
  select(id, .predictions, training_tbl, testing_tbl) %>%
  mutate(assessment_tbl = pmap(list(training_tbl, testing_tbl, .predictions),
                               function(training_tbl, testing_tbl, .predictions) {
                                 testing_tbl %>%
                                   dplyr::bind_cols(.predictions %>% select(.pred)) %>%
                                   dplyr::bind_rows(training_tbl) %>%
                                   dplyr::mutate(.type = ifelse(is.na(.pred), "Training", "Testing")) %>%
                                   dplyr::arrange(date)
                                 
                               })) %>%
  select(id, assessment_tbl) %>%
  mutate(plot = map(assessment_tbl, function(x) {
    ggplot(data = x, aes(x = date, y = y, color = .type)) +
      geom_line() +
      geom_line(aes(x = date, y = .pred), color = "orange") +
      scale_color_manual(
        name = "Series",
        values = c(
          "Training" = "black",
          "Testing" = "lightblue",
          "Forecast" = "orange"
        )
      )
  }))

library(gridExtra)

grid.arrange(
  slice_plot$plot[[1]],
  slice_plot$plot[[2]],
  slice_plot$plot[[3]],
  slice_plot$plot[[4]],
  slice_plot$plot[[5]],
  ncol = 2
)
```




---

```{r}
sessionInfo()
```


